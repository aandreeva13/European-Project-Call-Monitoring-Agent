
LLM_PROVIDER=openai

# 1. API CONNECTION
# Velocity requires the /api endpoint (no /v1)
OPENAI_BASE_URL=https://chat.velocity.online/api
OPENAI_API_KEY= 

# 2. PROVIDER + MODEL SELECTION
# CRITICAL: force OpenAI-compatible provider mode (Velocity proxy)
LLM_PROVIDER=openai

LLM_MODEL=google_genai.gemini/gemini-3-pro-preview #critic

# Database
DATABASE_PATH=data/calls.db

# Scraping Configuration
REQUEST_TIMEOUT=30
MAX_RETRIES=3

# Output
REPORTS_DIR=output/reports

# Security
ALLOWED_HOSTS=localhost,127.0.0.1

OPENAI_MODEL = openai.openai/gpt-5.2 #planner
LLM_MODEL_REPORTER=verda.verda/Kimi-K2.5                 
